{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /home/pk/miniconda3/envs/note/lib/python3.9/site-packages (from scikit-learn) (1.23.4)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached scipy-1.9.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.1.3 scipy-1.9.3 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_data = torch.load('../faceEmbeddingModels/embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "\n",
    "class FaceDetect:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        print('Running on device: {}'.format(self.device))\n",
    "        self.mtcnn = MTCNN(image_size=112, margin=0, device=self.device)\n",
    "        self.resnet = InceptionResnetV1(pretrained='vggface2').eval().to(self.device)\n",
    "        saved_data = torch.load('../faceEmbeddingModels/embeddings.pt')\n",
    "        self.embeddings = saved_data['embeddings']\n",
    "        self.names = saved_data['names']\n",
    "\n",
    "    def getFaceEmbedding(self, img):\n",
    "        face, prob = self.mtcnn(img, return_prob=True)\n",
    "        if face is not None and prob > 0.70:\n",
    "            embedding = self.resnet(face.unsqueeze(0).to(self.device)).detach()\n",
    "            return embedding\n",
    "        else:\n",
    "            return None\n",
    "    def get_prediction(self, embedding):\n",
    "        dist_list = []\n",
    "        for idx, emb_db in enumerate(self.embeddings):\n",
    "            dist = torch.dist(embedding, emb_db).item()\n",
    "            dist_list.append(dist)\n",
    "        idx_min = dist_list.index(min(dist_list))\n",
    "        result_name = self.names[idx_min]\n",
    "        return result_name\n",
    "    def detect_face(self):\n",
    "        cv2.namedWindow(\"Predicted Name\")\n",
    "        vc = cv2.VideoCapture(0)\n",
    "\n",
    "        while True:\n",
    "            rval, frame = vc.read()\n",
    "            if frame is not None:\n",
    "                embedding = self.getFaceEmbedding(frame)\n",
    "                if embedding is not None:\n",
    "                    result_name = self.get_prediction(embedding)\n",
    "                    cv2.putText(frame, result_name, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            cv2.imshow(\"preview\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        cv2.destroyWindow(\"preview\")\n",
    "        vc.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FaceDetect().detect_face()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('note')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b838f0dfc1990a82af8731af54161d841f0d173f980e272663241d9aacf6f27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
